df_list_split<-pblapply(df_list,function(x){split(x,f=as.factor(x$index_trial))})
test<-df_list[[144]]
table(is.na(test$Event))
test<-
rm(df_list_split)
test<-pblapply(df_list,function(x){x<-x[!is.na(x$Event),]})
df_list<-test
rm(test)
#split each participant to trials
df_list_split<-pblapply(df_list,function(x){split(x,f=as.factor(x$index_trial))})
test<-df_list_split[[144]]
func_pd_preprocess<-function(x){
#define variables
Left_Diameter<-x$Left.Diameter
Right_Diameter<-x$Right.Diameter
RemoteTime<-x$RemoteTime
#constant for MAD caluclation
constant<-3 ##--> if change speed is higher than constant * median change --> values are excluded
#constant<-3 #default value
# STEP 1 - exclude invalid data ####
pl <- ifelse((Left_Diameter<2|Left_Diameter>8), NA, Left_Diameter)
pr <- ifelse((Right_Diameter<2|Right_Diameter>8), NA, Right_Diameter)
#table(is.na(pl))
#table(is.na(pr))
# STEP 2 - filtering ####
## A) normalized dilation speed, take into account time jumps with Remotetimestamps: ####
#maximum change in pd compared to last and next pd measurement
#Left
pl.speed1<-diff(pl)/diff(RemoteTime) #compared to last
pl.speed2<-diff(rev(pl))/diff(rev(RemoteTime)) #compared to next
pl.speed1<-c(NA,pl.speed1)
pl.speed2<-c(rev(pl.speed2),NA)
pl.speed<-pmax(pl.speed1,pl.speed2,na.rm=T)
rm(pl.speed1,pl.speed2)
#Right
pr.speed1<-diff(pr)/diff(RemoteTime)
pr.speed2<-diff(rev(pr))/diff(rev(RemoteTime))
pr.speed1<-c(NA,pr.speed1)
pr.speed2<-c(rev(pr.speed2),NA)
pr.speed<-pmax(pr.speed1,pr.speed2,na.rm=T)
rm(pr.speed1,pr.speed2)
#median absolute deviation -SPEED
#constant<-3
pl.speed.med<-median(pl.speed,na.rm=T)
pl.mad<-median(abs(pl.speed-pl.speed.med),na.rm = T)
pl.treshold.speed<-pl.speed.med+constant*pl.mad #treshold.speed units are mm/microsecond
#plot(abs(pl.speed))+abline(h=pl.treshold.speed)
pr.speed.med<-median(pr.speed,na.rm=T)
pr.mad<-median(abs(pr.speed-pr.speed.med),na.rm = T)
pr.treshold.speed<-pr.speed.med+constant*pr.mad #treshold.speed units are mm/microsecond
#plot(abs(pr.speed))+abline(h=pr.treshold.speed)
#correct pupil dilation for speed outliers
pl<-ifelse(abs(pl.speed)>pl.treshold.speed,NA,pl)
pr<-ifelse(abs(pr.speed)>pr.treshold.speed,NA,pr)
## B) delete data around blinks ####
#gaps=missing data sections > 75ms; Leonie: also <=250ms, otherwise not likely to be a blink
#to be excluded: samples within 50 ms of gaps -> +-25 (8 data points) oder 50?
# pl<-fun_blink_cor(pl)
# pr<-fun_blink_cor(pr)
## C) normalized dilation size - median absolute deviation -SIZE ####
#applies a two pass approach
#first pass: exclude deviation from trend line derived from all samples
#second pass: exclude deviation from trend line derived from samples passing first pass
#-_> reintroduction of sample that might have been falsely excluded due to outliers
#estimate smooth size based on sampling rate
smooth.length<-150 #measured in ms
#take sampling rate into account (300 vs. 120):
#smooth.size<-round(smooth.length/mean(diff(RemoteTime)/1000)) #timestamp resolution in microseconds
smooth.size<-round(smooth.length/median(diff(RemoteTime),na.rm=T)) #timestamp resolution in milliseconds
is.even<-function(x){x%%2==0}
smooth.size<-ifelse(is.even(smooth.size)==T,smooth.size+1,smooth.size) #make sure to be odd value (see runmed)
#Left
pl.smooth<-na.approx(pl,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - FIRST pass
pl.pass1<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass1<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
#Left
pl.smooth<-na.approx(pl.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - SECOND pass
pl.pass2<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass2<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
pl<-pl.pass2
pr<-pr.pass2
## D) sparsity filter - not applied ####
# STEP 3 - processing valid samples  ####
#take offset between left and right into account
pd.offset<-pl-pr
pd.offset<-na.approx(pd.offset,rule=2)
#mean pupil dilation across both eyes
pl <- ifelse(is.na(pl)==FALSE, pl, pr+pd.offset)
pr <- ifelse(is.na(pr)==FALSE, pr, pl-pd.offset)
#interpolation of NA (for <=300ms)
pl<-na.approx(pl, na.rm=F, maxgap=90, rule=2)
pr<-na.approx(pr, na.rm=F, maxgap=90, rule=2)
pd <- (pl+pr)/2
# end of function --> return ####
#detach(x)
x[,'pd']<-pd
return(x)
}
test<-lapply(test,func_pd_preprocess)
func_pd_preprocess<-function(x){
#define variables
Left_Diameter<-x$Left.Diameter
Right_Diameter<-x$Right.Diameter
RemoteTime<-x$RemoteTime
#constant for MAD caluclation
constant<-3 ##--> if change speed is higher than constant * median change --> values are excluded
#constant<-3 #default value
# STEP 1 - exclude invalid data ####
pl <- ifelse((Left_Diameter<2|Left_Diameter>8), NA, Left_Diameter)
pr <- ifelse((Right_Diameter<2|Right_Diameter>8), NA, Right_Diameter)
#table(is.na(pl))
#table(is.na(pr))
# STEP 2 - filtering ####
## A) normalized dilation speed, take into account time jumps with Remotetimestamps: ####
#maximum change in pd compared to last and next pd measurement
#Left
pl.speed1<-diff(pl)/diff(RemoteTime) #compared to last
pl.speed2<-diff(rev(pl))/diff(rev(RemoteTime)) #compared to next
pl.speed1<-c(NA,pl.speed1)
pl.speed2<-c(rev(pl.speed2),NA)
pl.speed<-pmax(pl.speed1,pl.speed2,na.rm=T)
rm(pl.speed1,pl.speed2)
#Right
pr.speed1<-diff(pr)/diff(RemoteTime)
pr.speed2<-diff(rev(pr))/diff(rev(RemoteTime))
pr.speed1<-c(NA,pr.speed1)
pr.speed2<-c(rev(pr.speed2),NA)
pr.speed<-pmax(pr.speed1,pr.speed2,na.rm=T)
rm(pr.speed1,pr.speed2)
#median absolute deviation -SPEED
#constant<-3
pl.speed.med<-median(pl.speed,na.rm=T)
pl.mad<-median(abs(pl.speed-pl.speed.med),na.rm = T)
pl.treshold.speed<-pl.speed.med+constant*pl.mad #treshold.speed units are mm/microsecond
#plot(abs(pl.speed))+abline(h=pl.treshold.speed)
pr.speed.med<-median(pr.speed,na.rm=T)
pr.mad<-median(abs(pr.speed-pr.speed.med),na.rm = T)
pr.treshold.speed<-pr.speed.med+constant*pr.mad #treshold.speed units are mm/microsecond
#plot(abs(pr.speed))+abline(h=pr.treshold.speed)
#correct pupil dilation for speed outliers
pl<-ifelse(abs(pl.speed)>pl.treshold.speed,NA,pl)
pr<-ifelse(abs(pr.speed)>pr.treshold.speed,NA,pr)
## B) delete data around blinks ####
#gaps=missing data sections > 75ms; Leonie: also <=250ms, otherwise not likely to be a blink
#to be excluded: samples within 50 ms of gaps -> +-25 (8 data points) oder 50?
# pl<-fun_blink_cor(pl)
# pr<-fun_blink_cor(pr)
## C) normalized dilation size - median absolute deviation -SIZE ####
#applies a two pass approach
#first pass: exclude deviation from trend line derived from all samples
#second pass: exclude deviation from trend line derived from samples passing first pass
#-_> reintroduction of sample that might have been falsely excluded due to outliers
#estimate smooth size based on sampling rate
smooth.length<-150 #measured in ms
#take sampling rate into account (300 vs. 120):
#smooth.size<-round(smooth.length/mean(diff(RemoteTime)/1000)) #timestamp resolution in microseconds
smooth.size<-round(smooth.length/median(diff(RemoteTime),na.rm=T)) #timestamp resolution in milliseconds
is.even<-function(x){x%%2==0}
smooth.size<-ifelse(is.even(smooth.size)==T,smooth.size+1,smooth.size) #make sure to be odd value (see runmed)
#Left
pl.smooth<-na.approx(pl,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - FIRST pass
pl.pass1<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass1<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
#Left
pl.smooth<-na.approx(pl.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - SECOND pass
pl.pass2<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass2<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
pl<-pl.pass2
pr<-pr.pass2
## D) sparsity filter - not applied ####
# STEP 3 - processing valid samples  ####
#take offset between left and right into account
pd.offset<-pl-pr
pd.offset<-na.approx(pd.offset,rule=2)
#mean pupil dilation across both eyes
pl <- ifelse(is.na(pl)==FALSE, pl, pr+pd.offset)
pr <- ifelse(is.na(pr)==FALSE, pr, pl-pd.offset)
#interpolation of NA (for <=300ms)
pl<-na.approx(pl, na.rm=F, maxgap=90, rule=2)
pr<-na.approx(pr, na.rm=F, maxgap=90, rule=2)
pd <- (pl+pr)/2
#calculate baseline pd - mean of first 250ms
baseline_pd<-mean(x$pd[x$time_event<=0.250],na.rm=T)
baseline_pd<-rep(baseline_pd,nrow(x))
#return pupillometry values
x[,'pd_baseline']<-baseline_pd
x[,'pd']<-pd
x[,'rpd']<-pd-baseline_pd
return(x)
}
test<-df_list_split[[144]]
test<-pblapply(test,func_pd_preprocess)
warnings()
test<-unsplit(test,f=as.factor(index_trial))
require(data.table)
test<-rbindlist(test)
hist(test$pd)
hist(test$rpd)
summary(test$rpd)
summary(test$baseline_pd)
hist(test$time_event)
hist(test$time_event[test$time_event<1])
baseline_pd<-test$pd[test$time_event<=0.250]
baseline_pd<-mean(test$pd[test$time_event<=0.250],na.rm=T)
rep(baseline_pd,nrow(test))
hist(test$pd_baseline)
table(is.na((test$pd_baseline))
table(is.na((test$pd_baseline)))
table(is.na((test$pd_baseline)))
func_pd_preprocess<-function(x){
#define variables
Left_Diameter<-x$Left.Diameter
Right_Diameter<-x$Right.Diameter
RemoteTime<-x$RemoteTime
#constant for MAD caluclation
constant<-3 ##--> if change speed is higher than constant * median change --> values are excluded
#constant<-3 #default value
# STEP 1 - exclude invalid data ####
pl <- ifelse((Left_Diameter<2|Left_Diameter>8), NA, Left_Diameter)
pr <- ifelse((Right_Diameter<2|Right_Diameter>8), NA, Right_Diameter)
#table(is.na(pl))
#table(is.na(pr))
# STEP 2 - filtering ####
## A) normalized dilation speed, take into account time jumps with Remotetimestamps: ####
#maximum change in pd compared to last and next pd measurement
#Left
pl.speed1<-diff(pl)/diff(RemoteTime) #compared to last
pl.speed2<-diff(rev(pl))/diff(rev(RemoteTime)) #compared to next
pl.speed1<-c(NA,pl.speed1)
pl.speed2<-c(rev(pl.speed2),NA)
pl.speed<-pmax(pl.speed1,pl.speed2,na.rm=T)
rm(pl.speed1,pl.speed2)
#Right
pr.speed1<-diff(pr)/diff(RemoteTime)
pr.speed2<-diff(rev(pr))/diff(rev(RemoteTime))
pr.speed1<-c(NA,pr.speed1)
pr.speed2<-c(rev(pr.speed2),NA)
pr.speed<-pmax(pr.speed1,pr.speed2,na.rm=T)
rm(pr.speed1,pr.speed2)
#median absolute deviation -SPEED
#constant<-3
pl.speed.med<-median(pl.speed,na.rm=T)
pl.mad<-median(abs(pl.speed-pl.speed.med),na.rm = T)
pl.treshold.speed<-pl.speed.med+constant*pl.mad #treshold.speed units are mm/microsecond
#plot(abs(pl.speed))+abline(h=pl.treshold.speed)
pr.speed.med<-median(pr.speed,na.rm=T)
pr.mad<-median(abs(pr.speed-pr.speed.med),na.rm = T)
pr.treshold.speed<-pr.speed.med+constant*pr.mad #treshold.speed units are mm/microsecond
#plot(abs(pr.speed))+abline(h=pr.treshold.speed)
#correct pupil dilation for speed outliers
pl<-ifelse(abs(pl.speed)>pl.treshold.speed,NA,pl)
pr<-ifelse(abs(pr.speed)>pr.treshold.speed,NA,pr)
## B) delete data around blinks ####
#gaps=missing data sections > 75ms; Leonie: also <=250ms, otherwise not likely to be a blink
#to be excluded: samples within 50 ms of gaps -> +-25 (8 data points) oder 50?
# pl<-fun_blink_cor(pl)
# pr<-fun_blink_cor(pr)
## C) normalized dilation size - median absolute deviation -SIZE ####
#applies a two pass approach
#first pass: exclude deviation from trend line derived from all samples
#second pass: exclude deviation from trend line derived from samples passing first pass
#-_> reintroduction of sample that might have been falsely excluded due to outliers
#estimate smooth size based on sampling rate
smooth.length<-150 #measured in ms
#take sampling rate into account (300 vs. 120):
#smooth.size<-round(smooth.length/mean(diff(RemoteTime)/1000)) #timestamp resolution in microseconds
smooth.size<-round(smooth.length/median(diff(RemoteTime),na.rm=T)) #timestamp resolution in milliseconds
is.even<-function(x){x%%2==0}
smooth.size<-ifelse(is.even(smooth.size)==T,smooth.size+1,smooth.size) #make sure to be odd value (see runmed)
#Left
pl.smooth<-na.approx(pl,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - FIRST pass
pl.pass1<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass1<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
#Left
pl.smooth<-na.approx(pl.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pl.smooth<-runmed(pl.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pl.smooth))!=0){pl.smooth<-runmed(pl.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pl.mad<-median(abs(pl-pl.smooth),na.rm=T)
#Right
pr.smooth<-na.approx(pr.pass1,na.rm=F,rule=2) #impute missing values with interpolation
#pr.smooth<-runmed(pr.smooth,k=smooth.size) #smooth algorithm by running median of 15 * 3.3ms
if(sum(!is.na(pr.smooth))!=0){pr.smooth<-runmed(pr.smooth,k=smooth.size)} #run smooth algo only if not all elements == NA
pr.mad<-median(abs(pr-pr.smooth),na.rm=T)
#correct pupil dilation for size outliers - SECOND pass
pl.pass2<-ifelse((pl>pl.smooth+constant*pl.mad)|(pl<pl.smooth-constant*pl.mad),NA,pl)
pr.pass2<-ifelse((pr>pr.smooth+constant*pr.mad)|(pr<pr.smooth-constant*pr.mad),NA,pr)
pl<-pl.pass2
pr<-pr.pass2
## D) sparsity filter - not applied ####
# STEP 3 - processing valid samples  ####
#take offset between left and right into account
pd.offset<-pl-pr
pd.offset<-na.approx(pd.offset,rule=2)
#mean pupil dilation across both eyes
pl <- ifelse(is.na(pl)==FALSE, pl, pr+pd.offset)
pr <- ifelse(is.na(pr)==FALSE, pr, pl-pd.offset)
#interpolation of NA (for <=300ms)
pl<-na.approx(pl, na.rm=F, maxgap=90, rule=2)
pr<-na.approx(pr, na.rm=F, maxgap=90, rule=2)
pd <- (pl+pr)/2
#calculate baseline pd - mean of first 250ms
baseline_pd<-mean(pd[x$time_event<=0.250],na.rm=T)
baseline_pd<-rep(baseline_pd,nrow(x))
#return pupillometry values
x[,'pd_baseline']<-baseline_pd
x[,'pd']<-pd
x[,'rpd']<-pd-baseline_pd
return(x)
}
test<-df_list_split[[144]]
test<-pblapply(test,func_pd_preprocess)
test<-rbindlist(test)
table(is.na((test$pd_baseline)))
hist(test$rpd)
hist(test$pd_baseline)
hist(test$rpd)
hist(test$pd)
test<-df_list_split[[47]]
test<-pblapply(test,func_pd_preprocess)
test<-rbindlist(test)
hist(test$pd)
hist(test$time_event[test$time_event<1])
hist(test$rpd)
hist(test$pd_baseline)
test<-pblapply(df_list_split,function(x){pblapply(x,func_pd_preprocess)})
test<-pblapply(test,rbindlist)
table(sapply(df_list,nrow),sapply(test,nrow))
sapply(df_list,nrow)
sapply(test,nrow)
hist(sapply(test,nrow))
hist(sapply(df_list,nrow))
df_list<-test
rm(test)
save(df_list,'C:/Users/nico/Desktop/mmn_leap_pd_preprocced')
save(df_list,file='C:/Users/nico/Desktop/mmn_leap_pd_preproccesed')
df<-rbindlist(df_list)
require(ggplot2)
length(sample(1:nrow(df),nrow(df)/10000))
table(df$Event)
test<-df[sample(1:nrow(df),nrow(df)/1000) & df$Event=='EEG_EVENT',]
test<-df[df$Event=='EEG_EVENT',]
test<-test[sample(1:nrow(test),nrow(test)/1000),]
ggplot(test,aes(x=time_event,y=rpd))+geom_smooth()
ggplot(test,aes(x=time_event,y=rpd,group==EventData,color=EventData))+geom_smooth()
table(test$Event,test$EventData)
ggplot(test,aes(x=EventData,y=rpd,group==EventData))+geom_boxplot()
ggplot(test,aes(x=time_event,y=pd,group==EventData,color=EventData))+geom_smooth()
ggplot(test,aes(x=EventData,y=baseline_pd,group==EventData))+geom_boxplot()
test<-df[df$Event=='EEG_EVENT',]
test<-test[sample(1:nrow(test),nrow(test)/100),]
ggplot(test,aes(x=time_event,y=pd,group==EventData,color=EventData))+geom_smooth()
with(test,by(rpd,EventData,psych::describe))
with(test,by(pd,EventData,psych::describe))
with(test,by(pd_baseline,EventData,psych::describe))
ggplot(test,aes(x=time_event,y=Right.Diameter,group==EventData,color=EventData))+geom_smooth()
with(test,by(Right.Diameter,EventData,psych::describe))
wants <- c("dplyr", #for select and mutate (ergänzt Datensatz um Spalten) function
"zoo", #required: na.approx
"ggplot2", #visuals
"openxlsx", #Read, Write and Edit xlsx Files
"readxl", #Read, Write and Edit xlsx Files
"WriteXLS", #Write and Edit xlsx Files
"emmeans", #linear mixed models
"effsize", #für Grafenoptik
"contrast", #für Grafenoptik
"lme4","lmerTest", #linear mixed models
"MatchIt", #sampel matching
"magrittr", #for pipe-operator %>%
"psych", #for describeBy, counting saccades
"tidyverse", #required
"cobalt"#possibly for matching. Generate balance tables and plots for covariates of groups
#preprocessed through matching, weighting or subclassification
)
has <- wants %in% rownames(installed.packages())
wants <- c("dplyr", #for select and mutate (ergänzt Datensatz um Spalten) function
"zoo", #required: na.approx
"ggplot2", #visuals
"openxlsx", #Read, Write and Edit xlsx Files
"readxl", #Read, Write and Edit xlsx Files
"WriteXLS", #Write and Edit xlsx Files
"emmeans", #linear mixed models
"effsize", #für Grafenoptik
"contrast", #für Grafenoptik
"lme4","lmerTest", #linear mixed models
"MatchIt", #sampel matching
"magrittr", #for pipe-operator %>%
"psych", #for describeBy, counting saccades
"tidyverse", #required
"cobalt",#possibly for matching. Generate balance tables and plots for covariates of groups
"data.table" #fread uses parallelization and thus mucd faster than read.csv
#preprocessed through matching, weighting or subclassification
)
has <- wants %in% rownames(installed.packages())
has
if(any(!has)) install.packages(wants[!has]) #Nico: repo CRAN ist default
install.packages(wants[!has])
install.packages(wants[!has])
install.packages(wants[!has])
has <- wants %in% rownames(installed.packages())
has
wants[!has]
#--> loaded packages
sessionInfo()
has <- wants %in% rownames(installed.packages())
wants[!has]
installed.packages()
wants[!has]
wants <- c("dplyr", #for select and mutate (ergänzt Datensatz um Spalten) function
"zoo", #required: na.approx
"ggplot2", #visuals
#"openxlsx", #Read, Write and Edit xlsx Files
"readxl", #Read, Write and Edit xlsx Files
"WriteXLS", #Write and Edit xlsx Files
"emmeans", #linear mixed models
"effsize", #für Grafenoptik
"contrast", #für Grafenoptik
"lme4","lmerTest", #linear mixed models
"MatchIt", #sampel matching
"magrittr", #for pipe-operator %>%
"psych", #for describeBy, counting saccades
"tidyverse", #required
"cobalt",#possibly for matching. Generate balance tables and plots for covariates of groups
"data.table" #fread uses parallelization and thus mucd faster than read.csv
#preprocessed through matching, weighting or subclassification
)
has <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has]) #Nico: repo CRAN ist default
install.packages(wants[!has])
has <- wants %in% rownames(installed.packages())
wants[!has]
install.packages('cobalt')
wants[!has]
has <- wants %in% rownames(installed.packages())
wants[!has]
install.packages('tidyverse')
install.packages("tidyverse")
install.packages("tidyverse")
require(tidyverse)
read.csv(file="C:/Users/nico/Downloads/citations.csv")
pubs<-read.csv(file="C:/Users/nico/Downloads/citations.csv")
View(pubs)
write.table(pubs, file='publications.tsv', quote=FALSE, sep='\t', col.names = NA)
getwd()
View(pubs)
View(pubs)
pubs<-read.table(file="publications.tsv",sep'\t')
pubs<-read.table(file="publications.tsv",sep='\t')
setwd('C:/Users/nico/PowerFolders/project_webpage/nicobast.github.io/markdown_generator')
pubs<-read.table(file="publications.tsv",sep='\t')
test<-read.table(file="publications.tsv",sep='\t')
setwd('C:/Users/nico/PowerFolders/project_webpage/nicobast.github.io/markdown_generator')
pubs<-read.csv(file="citations.csv")
write.table(pubs, file='publications.tsv', quote=FALSE, sep='\t', col.names = NA)
test<-read.table(file="publications.tsv",sep='\t')
?read.table
test<-read.table(file="publications.tsv",sep='\t', quote=""")
test<-read.table(file="publications.tsv",sep='\t', quote="")
test<-read.table(file="publications.tsv",sep='\t', quote="")
View(test)
test<-read.table(file="publications.tsv",sep='\t', quote="", header=T)
View(test)
test<-read.table(file="publications.tsv",sep='\t', quote="", header=T,row.names=1)
View(pubs)
load("C:/Users/nico/PowerFolders/Supervision_ETLeonie/emotionexpression_task/data_preprocessed_emoexp_090523.Rdata")
with(df_emoexp[df_emoexp$fixation==TRUE],hist(ts))
with(df_emoexp[df_emoexp$fixation==TRUE,],hist(ts))
with(df_emoexp[df_emoexp$fixation==TRUE,],summary(ts))
